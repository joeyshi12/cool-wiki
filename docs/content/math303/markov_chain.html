<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Markov Chain</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Markov Chain</h1>
<p class="subtitle"><a href="/">Return home</a></p>
</header>
<p><strong>Definition.</strong> Let <span
class="math inline">\(\{X_{n}\}\)</span> be a sequence of i.i.d. random
variables. <span class="math inline">\(\{X_n\}\)</span> is a Markov
Chain if for any <span class="math inline">\(n =
0,1,\ldots,\)</span></p>
<p><span class="math display">\[P(X_{n+1} = j \mid X_{n} = i) = P(X_{1}
= j \mid X_{0} = i)\quad \text{(Markov property)}.\]</span></p>
<p><span class="math inline">\(\{X_{n}\}\)</span> is a homogeneous
Markov chain if it has the following additional property:</p>
<p><span class="math display">\[P(X_{n+1} = i_{n+1} \mid X_{0} =
i_{0},\ldots X_{n} = i_{n})
= P(X_{n+1} = i_{n+1} \mid X_{n} = i_{n}).\]</span></p>
<p>Markov chains are often depicted as a directed multigraph, where the
states are vertices and edges <span class="math inline">\(ij\)</span>
are weighted by transition probabilities <span
class="math inline">\(p_{ij}\)</span>.</p>
<figure>
<img src="/assets/simple_chain.svg" alt="Simple Chain" />
<figcaption aria-hidden="true">Simple Chain</figcaption>
</figure>
<h2 id="transition-matrix">Transition Matrix</h2>
<p><strong>Definition.</strong> Let <span class="math inline">\(p_{ij} =
P(X_{1} = j \mid X_{0} = i)\)</span>. If the state space of <span
class="math inline">\(X_{n}\)</span> is finite, then we define the
transition matrix of the chain <span class="math inline">\(P\)</span> as
an <span class="math inline">\(m\times m\)</span> matrix, such that
<span class="math inline">\(P_{ij} = p_{ij}\)</span>, where <span
class="math inline">\(m\)</span> is the size of the state space of <span
class="math inline">\(X_{n}\)</span>.</p>
<p>Denote <span class="math inline">\(p_{ij}^{(n)} = P(X_n = j \mid X_0
= i)\)</span>. We can observe that</p>
<p><span class="math display">\[(P^2)_{ij} = \sum_{k} p_{ik}p_{kj} =
p_{ij}^{(2)}\]</span></p>
<p>by the law of total probability. By induction, we can see the
transition probabilities after <span class="math inline">\(n\)</span>
steps simplies to <span class="math inline">\(p_{ij}^{(n)} =
(P^{n})_{ij}\)</span>.</p>
<p>The following is another direct consequence of the law of total
probabilty:</p>
<p><span class="math display">\[p_{ij}^{(m+n)} = \sum_{k}
p_{ik}^{(m)}p_{kj}^{(n)}\quad \text{(Chapman-Kologorov
Equations)}\]</span></p>
<h2 id="communication-classes">Communication Classes</h2>
<p><strong>Definition.</strong> We say <span
class="math inline">\(j\)</span> is <strong>accessible</strong> from
<span class="math inline">\(i\)</span> (<span class="math inline">\(i\to
j\)</span>) if <span class="math inline">\(P(X_{n} = j \text{ for some }
n\mid X_{0} = i) &gt; 0\)</span>. That is to say, there exists a <span
class="math inline">\(i-j\)</span> path in the Markov chain. We say
<span class="math inline">\(i\)</span> <strong>communicates</strong>
with <span class="math inline">\(j\)</span> (<span
class="math inline">\(i\leftrightarrow j\)</span>) if we additionally
have <span class="math inline">\(j\to i\)</span>.</p>
<p>Communication between states is an equivalence relation and these
equivalence classes are called <strong>communication classes</strong>. A
communication class <span class="math inline">\(C\)</span> is called
<strong>closed</strong> if every state not in <span
class="math inline">\(C\)</span> is not accessible from any state in
<span class="math inline">\(C\)</span>. That is, <span
class="math inline">\(i\not\to j\)</span> for any <span
class="math inline">\(i\in{C}, j\not\in{C}\)</span>.</p>
<p>If a Markov chain has exactly 1 communication class, it is called
<strong>irreducible</strong>.</p>
<h2 id="period">Period</h2>
<p><strong>Definition.</strong> The <strong>period</strong> of a state
<span class="math inline">\(i\)</span> (<span
class="math inline">\(d(i)\)</span>) is the gcd of the length of all
closed walks in the Markov chain starting from <span
class="math inline">\(i\)</span>. The period of <span
class="math inline">\(i\)</span> can be written as</p>
<p><span class="math display">\[d_i = \gcd\{n\mid p_{ii}^{(n)} &gt;
0\}.\]</span></p>
<p>The period is a class property, so all states in the same
communication class has the same period.</p>
<p>If <span class="math inline">\(d(i) = 1\)</span>, we say <span
class="math inline">\(i\)</span> is <strong>aperiodic</strong>. If <span
class="math inline">\(C\)</span> is the communication class of <span
class="math inline">\(i\)</span>, so we may also say <span
class="math inline">\(C\)</span> is aperiodic.</p>
<h2 id="recurrence">Recurrence</h2>
<p><strong>Definition</strong>. Let <span class="math inline">\(f_i =
P(X_n = i\text{ for some } n\geq 1\mid X_0 = i)\)</span>.</p>
<ul>
<li>If <span class="math inline">\(f_i = 1\)</span>, then state <span
class="math inline">\(i\)</span> is <strong>recurrent</strong></li>
<li>If <span class="math inline">\(f_i &lt; 1\)</span>, then state <span
class="math inline">\(i\)</span> is <strong>transient</strong></li>
</ul>
<p>Since the probability of returning to a recurrent state <span
class="math inline">\(i\)</span> is <span
class="math inline">\(1\)</span>, we are guarenteed to return to <span
class="math inline">\(i\)</span> an infinite number of times. That is,
<span class="math inline">\(P(N_i = \infty \mid X_0 = i) = 1\)</span>,
where <span class="math inline">\(N_i :=\)</span> number of returns to
<span class="math inline">\(i\)</span> along some trajectory, which we
can denote by <span class="math inline">\(\{X_n\}\)</span>. Then,</p>
<p><span class="math display">\[\begin{align}
N_i &amp;= \sum_{n=0}^{\infty} \mathbb{1}[X_n = i] \\
E[N_i\mid X_0 = i] &amp;= \sum_{n=0}^{\infty} p_{ii}^{(n)} = \infty
\end{align}\]</span></p>
<p>if <span class="math inline">\(i\)</span> is recurrent and <span
class="math inline">\(\sum_{n=0}^{\infty} p_{ii}^{(n)} &lt;
\infty\)</span> if <span class="math inline">\(i\)</span> is
transient.</p>
<p>The following is commonly used to categorize chains with infinite
states as recurrent or transient:</p>
<p><strong>Proposition.</strong> A state <span
class="math inline">\(i\)</span> is recurrent if and only if <span
class="math inline">\(\sum_{n=0}^{\infty} p_{ii}^{(n)}\)</span>
diverges.</p>
<p><strong>Remark.</strong> Recurrence and transience are class
properties.</p>
<h2 id="more-notes">More Notes</h2>
<ul>
<li><a href="/content/math303/stationary_distribution.html">Stationary
Distribution</a></li>
</ul>
</body>
</html>
